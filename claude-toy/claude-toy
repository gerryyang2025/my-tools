#!/usr/bin/env python3
"""
claude-toy: AI Coding Agent control-flow example.
Implements Think -> Act -> Observe loop via OpenAI API or Anthropic API (e.g. MiniMax).
"""

import os
import json
import subprocess
import re
import urllib.parse
import urllib.request
from pathlib import Path
from typing import Optional
from openai import OpenAI

try:
    import anthropic
except ImportError:
    anthropic = None

# =============================================================================
# Config: load from openai_config.json first, then env vars and defaults
# =============================================================================

_SCRIPT_DIR = Path(__file__).resolve().parent
_CONFIG: dict = {}
_config_path = _SCRIPT_DIR / "openai_config.json"
if _config_path.exists():
    try:
        _CONFIG = json.loads(_config_path.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, OSError):
        pass

MODEL = _CONFIG.get("model") or os.environ.get("CLAUDE_TOY_MODEL", "gpt-4o")
BASH_TIMEOUT = int(os.environ.get("CLAUDE_TOY_BASH_TIMEOUT", "30"))
MAX_OUTPUT_LEN = int(os.environ.get("CLAUDE_TOY_MAX_OUTPUT", "2000"))
MAX_LIST_FILES = int(os.environ.get("CLAUDE_TOY_MAX_FILES", "50"))
MAX_AGENT_ITERATIONS = int(os.environ.get("CLAUDE_TOY_MAX_ITER", "30"))
NET_TIMEOUT = int(os.environ.get("CLAUDE_TOY_NET_TIMEOUT", "20"))
MAX_FETCH_BYTES = int(os.environ.get("CLAUDE_TOY_MAX_FETCH_BYTES", "200000"))
MAX_SEARCH_RESULTS = int(os.environ.get("CLAUDE_TOY_MAX_SEARCH_RESULTS", "5"))
ENABLE_NETWORK_TOOLS = os.environ.get("CLAUDE_TOY_ENABLE_NETWORK", "1") not in ("0", "false", "False")


def _openai_client() -> OpenAI:
    """Build OpenAI client from openai_config.json or env vars."""
    api_key = _CONFIG.get("api_key") or os.environ.get("OPENAI_API_KEY")
    base_url = _CONFIG.get("base_url")
    kwargs = {"api_key": api_key}
    if base_url:
        kwargs["base_url"] = base_url
    return OpenAI(**kwargs)


def _is_minimax() -> bool:
    """True if configured base_url is MiniMax (OpenAI-compatible endpoint)."""
    url = (_CONFIG.get("base_url") or "").lower()
    return "minimaxi" in url or "minimax" in url


def _use_anthropic() -> bool:
    """True if provider is Anthropic. Default (no provider) is OpenAI path."""
    p = (_CONFIG.get("provider") or os.environ.get("CLAUDE_TOY_PROVIDER", "openai")).lower()
    if p == "anthropic":
        return True
    if p == "openai":
        return False
    url = (_CONFIG.get("base_url") or "").lower()
    return "/anthropic" in url or url.endswith("anthropic")


def _anthropic_client():
    """Build Anthropic client from config or env (ANTHROPIC_API_KEY, ANTHROPIC_BASE_URL)."""
    if anthropic is None:
        raise RuntimeError("anthropic package required for provider=anthropic. Run: pip install anthropic")
    api_key = _CONFIG.get("api_key") or os.environ.get("ANTHROPIC_API_KEY")
    base_url = _CONFIG.get("base_url") or os.environ.get("ANTHROPIC_BASE_URL", "https://api.minimaxi.com/anthropic")
    return anthropic.Anthropic(api_key=api_key, base_url=base_url)


# =============================================================================
# 1. Define Tools
# =============================================================================

def _http_get(url: str, timeout_s: int = NET_TIMEOUT) -> tuple[int, str, bytes]:
    """
    Minimal HTTP GET helper (stdlib only).
    Returns: (status_code, content_type, body_bytes)
    """
    parsed = urllib.parse.urlparse(url)
    if parsed.scheme not in ("http", "https"):
        raise ValueError("Only http/https URLs are allowed")

    req = urllib.request.Request(
        url,
        headers={
            "User-Agent": "claude-toy/1.0 (+https://example.local)",
            "Accept": "text/html,application/json,text/plain,*/*;q=0.8",
        },
        method="GET",
    )
    with urllib.request.urlopen(req, timeout=timeout_s) as resp:
        status = int(getattr(resp, "status", 200))
        content_type = resp.headers.get("Content-Type", "") or ""
        body = resp.read(MAX_FETCH_BYTES + 1)
        if len(body) > MAX_FETCH_BYTES:
            body = body[:MAX_FETCH_BYTES]
        return status, content_type, body


def fetch_url(url: str) -> str:
    """Fetch a URL and return a truncated text preview (for browsing/search)."""
    if not ENABLE_NETWORK_TOOLS:
        return "Network tools are disabled (set CLAUDE_TOY_ENABLE_NETWORK=1 to enable)."

    print(f"  > [Fetch URL] {url}")
    try:
        status, content_type, body = _http_get(url)
        text = body.decode("utf-8", errors="replace")
        if len(text) > MAX_OUTPUT_LEN:
            text = text[:MAX_OUTPUT_LEN] + "\n... (output truncated)"
        return f"[HTTP {status}] {content_type}\n{text}".strip()
    except Exception as e:
        return f"Fetch failed: {e!r}"


def web_search(query: str, max_results: int = MAX_SEARCH_RESULTS) -> str:
    """
    Lightweight web search using DuckDuckGo HTML endpoint (no extra deps).
    Returns top results as text so the model can decide next steps.
    """
    if not ENABLE_NETWORK_TOOLS:
        return "Network tools are disabled (set CLAUDE_TOY_ENABLE_NETWORK=1 to enable)."

    q = query.strip()
    if not q:
        return "Query is empty."

    max_results = max(1, min(int(max_results), 10))
    url = "https://duckduckgo.com/html/?" + urllib.parse.urlencode({"q": q})
    print(f"  > [Web search] {q}")

    try:
        status, content_type, body = _http_get(url)
        html = body.decode("utf-8", errors="replace")

        # Very simple extraction for DDG HTML.
        # Title/link: <a rel="nofollow" class="result__a" href="...">Title</a>
        # Snippet:    <a class="result__snippet"...>...</a> or <span class="result__snippet">...</span>
        link_re = re.compile(r'<a[^>]*class="result__a"[^>]*href="([^"]+)"[^>]*>(.*?)</a>', re.IGNORECASE | re.DOTALL)
        snippet_re = re.compile(r'class="result__snippet"[^>]*>(.*?)</', re.IGNORECASE | re.DOTALL)

        links = link_re.findall(html)
        snippets = snippet_re.findall(html)

        def _clean(s: str) -> str:
            s = re.sub(r"<[^>]+>", "", s)
            s = s.replace("&amp;", "&").replace("&quot;", "\"").replace("&#39;", "'")
            s = re.sub(r"\s+", " ", s).strip()
            return s

        lines: list[str] = []
        lines.append(f"Query: {q}")
        lines.append(f"Source: {url}")
        lines.append(f"Status: HTTP {status} ({content_type})")
        lines.append("")

        count = 0
        for i, (href, title_html) in enumerate(links):
            if count >= max_results:
                break
            title = _clean(title_html)
            href = _clean(href)
            snippet = _clean(snippets[i]) if i < len(snippets) else ""
            lines.append(f"{count + 1}. {title}")
            lines.append(f"   {href}")
            if snippet:
                lines.append(f"   {snippet}")
            lines.append("")
            count += 1

        if count == 0:
            preview = html[: min(len(html), 800)]
            lines.append("No results parsed. Raw preview:")
            lines.append(preview)

        out = "\n".join(lines).strip()
        if len(out) > MAX_OUTPUT_LEN:
            out = out[:MAX_OUTPUT_LEN] + "\n... (output truncated)"
        return out
    except Exception as e:
        return f"Search failed: {e!r}"


def execute_bash(command: str) -> str:
    """Run a bash command; return stdout+stderr, or an error string on timeout/exception."""
    print(f"  > [Run command] \033[93m{command}\033[0m")
    try:
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            timeout=BASH_TIMEOUT,
            encoding="utf-8",
            errors="replace",
        )
        output = (result.stdout or "") + (result.stderr or "")
        if output:
            print(f"  > [Output]\n{output.rstrip()}")
        if len(output) > MAX_OUTPUT_LEN:
            output = output[:MAX_OUTPUT_LEN] + "\n... (output truncated)"
        out = output.strip() or "(no output)"
        if result.returncode != 0:
            out = f"[exit code {result.returncode}]\n{out}"
        return out
    except subprocess.TimeoutExpired:
        msg = f"Command timed out (>{BASH_TIMEOUT}s)"
        print(f"  > [Error] {msg}")
        return msg
    except Exception as e:
        msg = f"Execution failed: {e!r}"
        print(f"  > [Error] {msg}")
        return msg


def read_file(path: str) -> str:
    """Read file contents with line numbers for easier reference."""
    print(f"  > [Read file] {path}")
    p = Path(path).resolve()
    if not p.exists():
        return f"File not found: {path}"
    if not p.is_file():
        return f"Path is not a file: {path}"
    try:
        content = p.read_text(encoding="utf-8", errors="replace")
    except OSError as e:
        return f"Read failed: {e!r}"
    lines = content.splitlines()
    numbered = [f"{i + 1:4d} | {line}" for i, line in enumerate(lines)]
    return "\n".join(numbered)


def write_file(path: str, content: str) -> str:
    """Create or overwrite file; create parent dirs if missing."""
    print(f"  > [Write file] {path}")
    p = Path(path).resolve()
    try:
        p.parent.mkdir(parents=True, exist_ok=True)
        p.write_text(content, encoding="utf-8")
        return f"Wrote {len(content)} bytes to {path}"
    except OSError as e:
        return f"Write failed: {e!r}"


def list_files(path: str = ".") -> str:
    """List files under directory recursively (skip dotfiles), up to MAX_LIST_FILES entries."""
    print(f"  > [List files] {path}")
    root = Path(path).resolve()
    if not root.exists():
        return f"Directory not found: {path}"
    if not root.is_dir():
        return f"Path is not a directory: {path}"
    file_list: list[str] = []
    for entry in root.rglob("*"):
        if entry.is_file() and not entry.name.startswith("."):
            try:
                file_list.append(str(entry.relative_to(root)))
            except ValueError:
                continue
    file_list.sort()
    result = "\n".join(file_list[:MAX_LIST_FILES])
    if len(file_list) > MAX_LIST_FILES:
        result += f"\n... (total {len(file_list)} files, showing first {MAX_LIST_FILES})"
    print(f"  > Files:\n{result}")
    return result


# =============================================================================
# 2. Define Tool Schemas
# =============================================================================

TOOLS_SCHEMA = [
    {
        "type": "function",
        "function": {
            "name": "web_search",
            "description": "Search the web for a query and return top results (title, url, snippet).",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "Search query"},
                    "max_results": {"type": "integer", "description": "Max results (1-10)"},
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "fetch_url",
            "description": "Fetch a URL and return a truncated text preview (for reading docs/pages).",
            "parameters": {
                "type": "object",
                "properties": {
                    "url": {"type": "string", "description": "http/https URL to fetch"},
                },
                "required": ["url"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "execute_bash",
            "description": "Execute a shell command. Use for running tests, installing deps, or file operations.",
            "parameters": {
                "type": "object",
                "properties": {
                    "command": {"type": "string", "description": "Bash command to run"}
                },
                "required": ["command"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": "Read file contents. Output includes line numbers.",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "File path"}
                },
                "required": ["path"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "write_file",
            "description": "Create or overwrite file with given content.",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "File path"},
                    "content": {"type": "string", "description": "Full content to write"},
                },
                "required": ["path", "content"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "list_files",
            "description": "List project file structure.",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "Directory path, default '.'"}
                },
                "required": [],
            },
        },
    },
]

AVAILABLE_FUNCTIONS = {
    "web_search": web_search,
    "fetch_url": fetch_url,
    "execute_bash": execute_bash,
    "read_file": read_file,
    "write_file": write_file,
    "list_files": list_files,
}


def run_tool(name: str, args: dict) -> str:
    """Execute a tool by name with given args; returns result string or error message. Shared by OpenAI and Anthropic paths."""
    if name not in AVAILABLE_FUNCTIONS:
        return f"Error: unknown tool {name}"
    try:
        return AVAILABLE_FUNCTIONS[name](**args)
    except TypeError as e:
        return f"Call args error: {e!r}"
    except Exception as e:
        return f"Tool execution error: {e!r}"


def _anthropic_tools():
    """Convert TOOLS_SCHEMA (OpenAI format) to Anthropic tools format (name, description, input_schema)."""
    out = []
    for t in TOOLS_SCHEMA:
        fn = t.get("function") or t
        out.append({
            "name": fn.get("name", ""),
            "description": fn.get("description", ""),
            "input_schema": fn.get("parameters", {"type": "object", "properties": {}, "required": []}),
        })
    return out


# =============================================================================
# 3. Agent Loop
# =============================================================================

EXIT_COMMANDS = ("exit", "quit", "q")
PROMPT_USER = "\nðŸ‘¤ You: "
PROMPT_THINKING = "\nðŸ¤– Thinking: "
PROMPT_REPLY = "\nðŸ¤– Reply:\n"
MAX_TOKENS = 4096

SYSTEM_PROMPT = """
You are an intelligent coding assistant.
Your goal is to help users write, debug, and understand code.

Guidelines:
1. Before changing code, use list_files to inspect project structure or read_file to read relevant files.
2. After editing files, run code or tests to verify (use execute_bash).
3. If you need up-to-date information, use web_search and then fetch_url to read the primary source.
4. Keep answers brief and focused on solving the task.
"""


def _read_user_input() -> tuple[Optional[str], bool]:
    """Read one line from user. Returns (content_or_None, exit_requested)."""
    line = input(PROMPT_USER).strip()
    if not line:
        return None, False
    if line.lower() in EXIT_COMMANDS:
        print("Bye!")
        return None, True
    return line, False


def _run_anthropic_loop(system_prompt: str) -> None:
    """Agent loop using Anthropic API (MiniMax anthropic endpoint). Preserves full response.content per doc."""
    client = _anthropic_client()
    tools = _anthropic_tools()
    anth_messages: list = []

    while True:
        try:
            user_input, exit_requested = _read_user_input()
            if exit_requested:
                break
            if user_input is None:
                continue

            anth_messages.append({"role": "user", "content": [{"type": "text", "text": user_input}]})
            iterations = 0

            while iterations < MAX_AGENT_ITERATIONS:
                iterations += 1
                response = client.messages.create(
                    model=MODEL,
                    max_tokens=MAX_TOKENS,
                    system=system_prompt,
                    messages=anth_messages,
                    tools=tools,
                    tool_choice="auto",
                    temperature=1.0,
                )
                anth_messages.append({"role": "assistant", "content": response.content})

                thinking_parts = []
                text_parts = []
                tool_use_blocks = []
                for block in response.content:
                    if getattr(block, "type", None) == "thinking":
                        thinking_parts.append(getattr(block, "thinking", "") or "")
                    elif getattr(block, "type", None) == "text":
                        text_parts.append(getattr(block, "text", "") or "")
                    elif getattr(block, "type", None) == "tool_use":
                        tool_use_blocks.append(block)

                if thinking_parts:
                    print(f"{PROMPT_THINKING}{' '.join(thinking_parts).strip() or '(calling tools...)'}")
                elif tool_use_blocks:
                    print(f"{PROMPT_THINKING}(calling tools...)")

                if not tool_use_blocks:
                    reply = " ".join(text_parts).strip() or "(no text reply)"
                    print(f"{PROMPT_REPLY}{reply}")
                    break

                tool_results = []
                for block in tool_use_blocks:
                    name = getattr(block, "name", "") or ""
                    raw = getattr(block, "input", None)
                    if isinstance(raw, dict):
                        args = raw
                    elif isinstance(raw, str):
                        try:
                            args = json.loads(raw)
                        except json.JSONDecodeError:
                            args = {}
                    else:
                        args = {}
                    tool_use_id = getattr(block, "id", "") or ""
                    result = run_tool(name, args)
                    tool_results.append({"type": "tool_result", "tool_use_id": tool_use_id, "content": str(result)})

                anth_messages.append({"role": "user", "content": tool_results})
            else:
                print(f"\nâš ï¸ Max iterations ({MAX_AGENT_ITERATIONS}) reached. Stopping.")

        except KeyboardInterrupt:
            print("\nCancelled.")
            break
        except Exception as e:
            print(f"\nError: {e}")
            break


def _openai_assistant_message_for_history(message) -> dict:
    """Build assistant message dict for next request when using MiniMax (reasoning_details must be retained)."""
    if not _is_minimax() or not getattr(message, "reasoning_details", None):
        return message
    try:
        msg_dict = message.model_dump() if hasattr(message, "model_dump") else {}
    except Exception:
        msg_dict = {}
    msg_dict = msg_dict if isinstance(msg_dict, dict) else {}
    msg_dict.setdefault("role", "assistant")
    msg_dict.setdefault("content", getattr(message, "content", None))
    if getattr(message, "tool_calls", None):
        def _tc_dict(tc):
            return tc.model_dump() if hasattr(tc, "model_dump") else {
                "id": getattr(tc, "id", ""),
                "type": "function",
                "function": {"name": getattr(tc.function, "name", ""), "arguments": getattr(tc.function, "arguments", "{}")},
            }
        msg_dict["tool_calls"] = [_tc_dict(tc) for tc in message.tool_calls]
    msg_dict["reasoning_details"] = message.reasoning_details
    return msg_dict


def _openai_thinking_text(message) -> str:
    """Extract thinking text from OpenAI response (content or reasoning_details)."""
    text = message.content or ""
    if getattr(message, "reasoning_details", None):
        for d in message.reasoning_details:
            if isinstance(d, dict) and d.get("text"):
                text = text or d["text"]
                break
    return text or "(calling tools...)"


def _run_openai_loop() -> None:
    """Agent loop using OpenAI-compatible API (OpenAI or MiniMax)."""
    client = _openai_client()
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    create_kwargs = {
        "model": MODEL,
        "messages": messages,
        "tools": TOOLS_SCHEMA,
        "tool_choice": "auto",
        "max_tokens": MAX_TOKENS,
    }
    if _is_minimax():
        create_kwargs["extra_body"] = {"reasoning_split": True}
        create_kwargs["temperature"] = 1.0

    while True:
        try:
            user_input, exit_requested = _read_user_input()
            if exit_requested:
                break
            if user_input is None:
                continue

            messages.append({"role": "user", "content": user_input})
            iterations = 0

            while iterations < MAX_AGENT_ITERATIONS:
                iterations += 1
                response = client.chat.completions.create(**create_kwargs)

                if not response.choices:
                    print("\nâš ï¸ API returned no valid result. Please retry.")
                    break
                message = response.choices[0].message
                messages.append(_openai_assistant_message_for_history(message))

                if message.tool_calls:
                    print(f"{PROMPT_THINKING}{_openai_thinking_text(message)}")

                    for tool_call in message.tool_calls:
                        name = tool_call.function.name
                        raw = tool_call.function.arguments or "{}"
                        try:
                            args = json.loads(raw)
                        except json.JSONDecodeError as e:
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "content": f"Tool args parse failed: {e!r}\nRaw: {raw[:200]}",
                            })
                            continue
                        result = run_tool(name, args)
                        messages.append({"role": "tool", "tool_call_id": tool_call.id, "content": str(result)})
                else:
                    print(f"{PROMPT_REPLY}{message.content or '(no text reply)'}")
                    break
            else:
                print(f"\nâš ï¸ Max iterations ({MAX_AGENT_ITERATIONS}) reached. Stopping.")

        except KeyboardInterrupt:
            print("\nCancelled.")
            break
        except Exception as e:
            print(f"\nError: {e}")
            break


def _print_banner(provider_label: str = "") -> None:
    """Print REPL banner with model and max iterations."""
    label = f" [{provider_label}]" if provider_label else ""
    print(f"ðŸ¤– claude-toy started{label} (type exit/quit/q to exit)")
    print(f"   Model: {MODEL} | Max iterations: {MAX_AGENT_ITERATIONS}")
    print("--------------------------------------------")


def run_toy_claude() -> None:
    """Start REPL: read user input, run model think/tool loop until final reply."""
    if _use_anthropic():
        _print_banner("Anthropic")
        _run_anthropic_loop(SYSTEM_PROMPT)
    else:
        _print_banner()
        _run_openai_loop()


if __name__ == "__main__":
    run_toy_claude()